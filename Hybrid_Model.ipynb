{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary methods from tweepy library\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import tweepy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables that contains the user credentials to access Twitter API \n",
    "access_token = \"200806633-2lHSXdGZDcfrYCkjTgfsD2Pal7O15WyTlqjVidib\"\n",
    "access_token_secret = \"5SEAwVu5j7o06ZWH0RIxzJvyZyLTkJp1jrxfHvBrpN2rn\"\n",
    "consumer_key = \"WGIxZngZosqttf0ZvtP3Pk05n\"\n",
    "consumer_secret = \"joD4U7jzJ0rjJrHA1QUW78wOXC007LwqcbAPxEVOs3N4wpaYBu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a basic listener that just prints received tweets to stdout.\n",
    "class StdOutListener(StreamListener):\n",
    "\n",
    "    def on_data(self, data):\n",
    "        print(data)\n",
    "        return True\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)  \n",
    "auth.set_access_token(access_token, access_token_secret)  \n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71201743\n"
     ]
    }
   ],
   "source": [
    "#screen_name = 'ArvindKejriwal'\n",
    "#screen_name = 'Bharat_Sardana_'\n",
    "#screen_name = 'tarunkjuyal'\n",
    "#screen_name = 'yi_twitts'\n",
    "#screen_name = 'tmj_clt_util'    #social bot\n",
    "screen_name = 'imVkohli'\n",
    "\n",
    "user = api.get_user(screen_name)\n",
    "\n",
    "print(user.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virat Kohli\n",
      "imVkohli\n",
      "2029\n",
      "33225790\n",
      "58\n",
      "192\n",
      "7969\n"
     ]
    }
   ],
   "source": [
    "# Twitter account details\n",
    "print(user.name)\n",
    "print(user.screen_name)\n",
    "print(user.statuses_count)\n",
    "print(user.followers_count)\n",
    "print(user.friends_count)\n",
    "print(user.favourites_count)\n",
    "print(user.listed_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('virat kohli', 'imvkohli')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Weight of name and screen name\n",
    "name = user.name.lower()\n",
    "screen_name = user.screen_name.lower()\n",
    "\n",
    "name, screen_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxSubsequence(screen_name, name): \n",
    "    # find the length of the strings \n",
    "    m = len(screen_name) \n",
    "    n = len(name) \n",
    "  \n",
    "    # declaring the array for storing the dp values \n",
    "    L = [[None]*(n + 1) for i in range(m + 1)] \n",
    "  \n",
    "    \"\"\"Following steps build L[m + 1][n + 1] in bottom up fashion \n",
    "    Note: L[i][j] contains length of LCS of X[0..i-1] \n",
    "    and Y[0..j-1]\"\"\"\n",
    "    for i in range(m + 1): \n",
    "        for j in range(n + 1): \n",
    "            if i == 0 or j == 0 : \n",
    "                L[i][j] = 0\n",
    "            elif screen_name[i-1] == name[j-1]: \n",
    "                L[i][j] = L[i-1][j-1]+1\n",
    "            else: \n",
    "                L[i][j] = max(L[i-1][j], L[i][j-1]) \n",
    "  \n",
    "    # L[m][n] contains the length of LCS of X[0..n-1] & Y[0..m-1] \n",
    "    return L[m][n] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5454545454545454"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subseq = maxSubsequence(screen_name, name)\n",
    "name_wt = subseq/len(name)\n",
    "name_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['name','screen_name','statuses_count','followers_count','friends_count','favourites_count','listed_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.45454545e-01, 2.02900000e+03, 3.32192890e+07, 5.80000000e+01,\n",
       "        1.92000000e+02, 7.96800000e+03]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array([name_wt,user.statuses_count,user.followers_count,user.friends_count,user.favourites_count,user.listed_count]).reshape(1, -1)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    label :  0  = genuine users\n",
    "             1  = fake users\n",
    "''' \n",
    "\n",
    "y_test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import k_nearest_neighbors as my_k_nearest_neighbors\n",
    "import neural_network as my_neural_network\n",
    "import decision_tree as my_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location='data/twitter_dataset.csv'\n",
    "dataset = pd.read_csv(dataset_location, encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[]\n",
    "for attributes in dataset.columns:\n",
    "    if attributes != 'label':\n",
    "        features.append(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Megha_Mayank\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((6945, 6), (6945,))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = dataset.as_matrix(columns = features) # Features\n",
    "y_train = dataset.label\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained knn\n",
      "trained decision tree\n",
      "Epoch 1/150\n",
      "6945/6945 [==============================] - 0s 43us/step - loss: 4.8316 - accuracy: 0.5984\n",
      "Epoch 2/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 1.7280 - accuracy: 0.7711\n",
      "Epoch 3/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 1.2957 - accuracy: 0.8465\n",
      "Epoch 4/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.4831 - accuracy: 0.8687\n",
      "Epoch 5/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.4486 - accuracy: 0.8681\n",
      "Epoch 6/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.4756 - accuracy: 0.8848\n",
      "Epoch 7/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.4608 - accuracy: 0.8767\n",
      "Epoch 8/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.4087 - accuracy: 0.8698\n",
      "Epoch 9/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.4685 - accuracy: 0.8661\n",
      "Epoch 10/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.4838 - accuracy: 0.8727\n",
      "Epoch 11/150\n",
      "6945/6945 [==============================] - 0s 13us/step - loss: 0.3913 - accuracy: 0.8898\n",
      "Epoch 12/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.3682 - accuracy: 0.8831\n",
      "Epoch 13/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.3923 - accuracy: 0.8770\n",
      "Epoch 14/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.3495 - accuracy: 0.8844\n",
      "Epoch 15/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.3334 - accuracy: 0.8852\n",
      "Epoch 16/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.3284 - accuracy: 0.8844\n",
      "Epoch 17/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.3129 - accuracy: 0.8960\n",
      "Epoch 18/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.3124 - accuracy: 0.8994\n",
      "Epoch 19/150\n",
      "6945/6945 [==============================] - 0s 14us/step - loss: 0.3290 - accuracy: 0.8802\n",
      "Epoch 20/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.3104 - accuracy: 0.8960\n",
      "Epoch 21/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2943 - accuracy: 0.8995\n",
      "Epoch 22/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.3046 - accuracy: 0.8962\n",
      "Epoch 23/150\n",
      "6945/6945 [==============================] - 0s 13us/step - loss: 0.2912 - accuracy: 0.8949\n",
      "Epoch 24/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.3112 - accuracy: 0.9032\n",
      "Epoch 25/150\n",
      "6945/6945 [==============================] - ETA: 0s - loss: 0.5148 - accuracy: 0.90 - 0s 12us/step - loss: 0.5349 - accuracy: 0.8934\n",
      "Epoch 26/150\n",
      "6945/6945 [==============================] - 0s 13us/step - loss: 0.4379 - accuracy: 0.8801\n",
      "Epoch 27/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.4413 - accuracy: 0.8842\n",
      "Epoch 28/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.3526 - accuracy: 0.8854\n",
      "Epoch 29/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.3264 - accuracy: 0.8973\n",
      "Epoch 30/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.3252 - accuracy: 0.9044\n",
      "Epoch 31/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.3091 - accuracy: 0.9067\n",
      "Epoch 32/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.3094 - accuracy: 0.9135\n",
      "Epoch 33/150\n",
      "6945/6945 [==============================] - 0s 13us/step - loss: 0.2913 - accuracy: 0.9186\n",
      "Epoch 34/150\n",
      "6945/6945 [==============================] - 0s 13us/step - loss: 0.2964 - accuracy: 0.9179\n",
      "Epoch 35/150\n",
      "6945/6945 [==============================] - 0s 13us/step - loss: 0.2601 - accuracy: 0.9212\n",
      "Epoch 36/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2581 - accuracy: 0.9199\n",
      "Epoch 37/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2578 - accuracy: 0.9197\n",
      "Epoch 38/150\n",
      "6945/6945 [==============================] - 0s 13us/step - loss: 0.3179 - accuracy: 0.9188\n",
      "Epoch 39/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2960 - accuracy: 0.9210\n",
      "Epoch 40/150\n",
      "6945/6945 [==============================] - 0s 13us/step - loss: 0.2690 - accuracy: 0.9269\n",
      "Epoch 41/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2811 - accuracy: 0.9227\n",
      "Epoch 42/150\n",
      "6945/6945 [==============================] - ETA: 0s - loss: 0.2787 - accuracy: 0.93 - 0s 12us/step - loss: 0.2688 - accuracy: 0.9267\n",
      "Epoch 43/150\n",
      "6945/6945 [==============================] - 0s 13us/step - loss: 0.2801 - accuracy: 0.9257\n",
      "Epoch 44/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2846 - accuracy: 0.9238\n",
      "Epoch 45/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2412 - accuracy: 0.9326\n",
      "Epoch 46/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2583 - accuracy: 0.9299\n",
      "Epoch 47/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2400 - accuracy: 0.9310\n",
      "Epoch 48/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2332 - accuracy: 0.9338\n",
      "Epoch 49/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2467 - accuracy: 0.9310\n",
      "Epoch 50/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2685 - accuracy: 0.9281\n",
      "Epoch 51/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2284 - accuracy: 0.9362\n",
      "Epoch 52/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2097 - accuracy: 0.9427\n",
      "Epoch 53/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2193 - accuracy: 0.9371\n",
      "Epoch 54/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2142 - accuracy: 0.9382\n",
      "Epoch 55/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2200 - accuracy: 0.9375\n",
      "Epoch 56/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2137 - accuracy: 0.9402\n",
      "Epoch 57/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2108 - accuracy: 0.9402\n",
      "Epoch 58/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2216 - accuracy: 0.9381\n",
      "Epoch 59/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.2179 - accuracy: 0.9417\n",
      "Epoch 60/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2307 - accuracy: 0.9381\n",
      "Epoch 61/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1909 - accuracy: 0.9450\n",
      "Epoch 62/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.2037 - accuracy: 0.9388\n",
      "Epoch 63/150\n",
      "6945/6945 [==============================] - 0s 13us/step - loss: 0.2515 - accuracy: 0.9411\n",
      "Epoch 64/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1899 - accuracy: 0.9434\n",
      "Epoch 65/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1824 - accuracy: 0.9454\n",
      "Epoch 66/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1767 - accuracy: 0.9480\n",
      "Epoch 67/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1898 - accuracy: 0.9451\n",
      "Epoch 68/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2107 - accuracy: 0.9433\n",
      "Epoch 69/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2024 - accuracy: 0.9385\n",
      "Epoch 70/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1879 - accuracy: 0.9479\n",
      "Epoch 71/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1661 - accuracy: 0.9522\n",
      "Epoch 72/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1569 - accuracy: 0.9515\n",
      "Epoch 73/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1652 - accuracy: 0.9522\n",
      "Epoch 74/150\n",
      "6945/6945 [==============================] - 0s 13us/step - loss: 0.1693 - accuracy: 0.9500\n",
      "Epoch 75/150\n",
      "6945/6945 [==============================] - 0s 13us/step - loss: 0.1743 - accuracy: 0.9463\n",
      "Epoch 76/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1465 - accuracy: 0.9515\n",
      "Epoch 77/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1348 - accuracy: 0.9557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1519 - accuracy: 0.9539\n",
      "Epoch 79/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1432 - accuracy: 0.9518\n",
      "Epoch 80/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1386 - accuracy: 0.9557\n",
      "Epoch 81/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1264 - accuracy: 0.9604\n",
      "Epoch 82/150\n",
      "6945/6945 [==============================] - 0s 13us/step - loss: 0.1467 - accuracy: 0.9542\n",
      "Epoch 83/150\n",
      "6945/6945 [==============================] - 0s 13us/step - loss: 0.1290 - accuracy: 0.9565\n",
      "Epoch 84/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1464 - accuracy: 0.9572\n",
      "Epoch 85/150\n",
      "6945/6945 [==============================] - 0s 13us/step - loss: 0.1493 - accuracy: 0.9542\n",
      "Epoch 86/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1616 - accuracy: 0.9571\n",
      "Epoch 87/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1535 - accuracy: 0.9555\n",
      "Epoch 88/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1475 - accuracy: 0.9572\n",
      "Epoch 89/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1583 - accuracy: 0.9542\n",
      "Epoch 90/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.2559 - accuracy: 0.9561\n",
      "Epoch 91/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.2629 - accuracy: 0.9572\n",
      "Epoch 92/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1776 - accuracy: 0.9590\n",
      "Epoch 93/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1469 - accuracy: 0.9610\n",
      "Epoch 94/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1664 - accuracy: 0.9536\n",
      "Epoch 95/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1450 - accuracy: 0.9572\n",
      "Epoch 96/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1284 - accuracy: 0.9621\n",
      "Epoch 97/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1448 - accuracy: 0.9568\n",
      "Epoch 98/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1500 - accuracy: 0.9564\n",
      "Epoch 99/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1295 - accuracy: 0.9607\n",
      "Epoch 100/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1450 - accuracy: 0.9575\n",
      "Epoch 101/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1343 - accuracy: 0.9590\n",
      "Epoch 102/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1200 - accuracy: 0.9594\n",
      "Epoch 103/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1217 - accuracy: 0.9601\n",
      "Epoch 104/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1293 - accuracy: 0.9594\n",
      "Epoch 105/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1393 - accuracy: 0.9581\n",
      "Epoch 106/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1289 - accuracy: 0.9585\n",
      "Epoch 107/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1294 - accuracy: 0.9604\n",
      "Epoch 108/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1407 - accuracy: 0.9588\n",
      "Epoch 109/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.2198 - accuracy: 0.9571\n",
      "Epoch 110/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1576 - accuracy: 0.9581\n",
      "Epoch 111/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1455 - accuracy: 0.9581\n",
      "Epoch 112/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1769 - accuracy: 0.9578\n",
      "Epoch 113/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1522 - accuracy: 0.9564\n",
      "Epoch 114/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1362 - accuracy: 0.9582\n",
      "Epoch 115/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1336 - accuracy: 0.9605\n",
      "Epoch 116/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1286 - accuracy: 0.9607\n",
      "Epoch 117/150\n",
      "6945/6945 [==============================] - 0s 13us/step - loss: 0.1224 - accuracy: 0.9616\n",
      "Epoch 118/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1288 - accuracy: 0.9618\n",
      "Epoch 119/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1845 - accuracy: 0.9477\n",
      "Epoch 120/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1361 - accuracy: 0.9603\n",
      "Epoch 121/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1331 - accuracy: 0.9591\n",
      "Epoch 122/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1325 - accuracy: 0.9603\n",
      "Epoch 123/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1305 - accuracy: 0.9613\n",
      "Epoch 124/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1240 - accuracy: 0.9631\n",
      "Epoch 125/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1426 - accuracy: 0.9598\n",
      "Epoch 126/150\n",
      "6945/6945 [==============================] - 0s 13us/step - loss: 0.1326 - accuracy: 0.9600\n",
      "Epoch 127/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1148 - accuracy: 0.9613\n",
      "Epoch 128/150\n",
      "6945/6945 [==============================] - 0s 13us/step - loss: 0.1237 - accuracy: 0.9590\n",
      "Epoch 129/150\n",
      "6945/6945 [==============================] - 0s 13us/step - loss: 0.1145 - accuracy: 0.9633\n",
      "Epoch 130/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1144 - accuracy: 0.9636\n",
      "Epoch 131/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1173 - accuracy: 0.9646\n",
      "Epoch 132/150\n",
      "6945/6945 [==============================] - 0s 14us/step - loss: 0.1206 - accuracy: 0.9621\n",
      "Epoch 133/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1207 - accuracy: 0.9636\n",
      "Epoch 134/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1147 - accuracy: 0.9667\n",
      "Epoch 135/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1143 - accuracy: 0.9637\n",
      "Epoch 136/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1132 - accuracy: 0.9631\n",
      "Epoch 137/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1131 - accuracy: 0.9634\n",
      "Epoch 138/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1080 - accuracy: 0.9660\n",
      "Epoch 139/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1175 - accuracy: 0.9617\n",
      "Epoch 140/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1024 - accuracy: 0.9654\n",
      "Epoch 141/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1132 - accuracy: 0.9640\n",
      "Epoch 142/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1071 - accuracy: 0.9660\n",
      "Epoch 143/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1027 - accuracy: 0.9660\n",
      "Epoch 144/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1040 - accuracy: 0.9679\n",
      "Epoch 145/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1030 - accuracy: 0.9685\n",
      "Epoch 146/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1010 - accuracy: 0.9690\n",
      "Epoch 147/150\n",
      "6945/6945 [==============================] - 0s 11us/step - loss: 0.1023 - accuracy: 0.9693\n",
      "Epoch 148/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1290 - accuracy: 0.9626\n",
      "Epoch 149/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1087 - accuracy: 0.9657\n",
      "Epoch 150/150\n",
      "6945/6945 [==============================] - 0s 12us/step - loss: 0.1469 - accuracy: 0.9603\n",
      "trained neural network\n"
     ]
    }
   ],
   "source": [
    "knn_model,knn_y_predict = my_k_nearest_neighbors.k_nearest_neighbours(X_train, X_test, y_train, y_test)\n",
    "print(\"trained knn\")\n",
    "\n",
    "dt_model,dt_y_predict = my_decision_tree.decision_tree(X_train, X_test, y_train, y_test)\n",
    "print(\"trained decision tree\")\n",
    "\n",
    "nn_model,nn_y_predict = my_neural_network.neural_network(X_train, X_test, y_train, y_test)\n",
    "print(\"trained neural network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** GENUINE USER *** \n"
     ]
    }
   ],
   "source": [
    "#for single test case\n",
    "if(nn_y_predict[0]+knn_y_predict[0]+dt_y_predict[0]>1):\n",
    "    hybrid_model_y = 1                #fake\n",
    "    print(\" ~~~ FAKE USER ~~~ \")\n",
    "else:\n",
    "    hybrid_model_y = 0                #genuine\n",
    "    print(\" *** GENUINE USER *** \")\n",
    "\n",
    "#print(hybrid_model_y)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), 0, 0)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_y_predict[0], knn_y_predict[0], dt_y_predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhybrid_model_y=[]\\nfor i in range(len(y_test)):\\n    if(nn_y_predict[i]+knn_y_predict[i]+dt_y_predict[i] >1):\\n        hybrid_model_y.append(1)\\n    else:\\n        hybrid_model_y.append(0)\\n\\nconf_matrix = confusion_matrix(y_test, hybrid_model_y)\\n\\n'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for multiple test cases\n",
    "\"\"\"\n",
    "hybrid_model_y=[]\n",
    "for i in range(len(y_test)):\n",
    "    if(nn_y_predict[i]+knn_y_predict[i]+dt_y_predict[i] >1):\n",
    "        hybrid_model_y.append(1)\n",
    "    else:\n",
    "        hybrid_model_y.append(0)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, hybrid_model_y)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
